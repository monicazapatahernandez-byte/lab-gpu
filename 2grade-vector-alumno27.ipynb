{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3431319e-2e6b-43c1-a2f6-61ccba592c21",
   "metadata": {},
   "source": [
    "## Evaluating a vectorial function on CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d142183-b6bb-42e7-ba9d-35bf0f91dc0c",
   "metadata": {},
   "source": [
    "### CPU: plain and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92dd336-9997-4323-80e4-f285e9cc2db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "8.69 ms ± 49.5 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "19.3 ms ± 76 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "19.5 ms ± 75 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "\n",
    "# Python plain implementation w/ numba \n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a*x[i]*x[i] + b*y[i] + c\n",
    "    return z\n",
    "\n",
    "# Numpy ufunc\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# size of the vectors\n",
    "size = 5_000_000\n",
    "\n",
    "# allocating and populating the vectors\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "c_cpu = np.zeros(size)\n",
    "\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10\n",
    "\n",
    "# Printing input values\n",
    "#print(a_cpu)\n",
    "#print(b_cpu)\n",
    "# Random function in Numpy always use float64\n",
    "print(a_cpu.dtype)\n",
    "\n",
    "c_cpu = grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "\n",
    "# Evaluating the time\n",
    "\n",
    "# Numba Python: huge improvement, better that numpy code\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# w/ a numpy ufunc manually coded\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# using the general numpy ufunc \n",
    "%timeit -n 5 -r 2 a*a_cpu**2 + b*b_cpu + c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69ec3ef-36a9-4304-85d4-2b34e8e9bab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 23 12:09:52 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1080        Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| 31%   43C    P0             38W /  180W |       0MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16fef2a-47a9-401f-b2e9-cbe9c51de56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo CuPy con copia CPU->GPU: 0.0055 s\n"
     ]
    }
   ],
   "source": [
    "#3.2\n",
    "\n",
    "import cupy as cp\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "# Copia explícita de los datos desde CPU a GPU\n",
    "x_gpu = cp.asarray(a_cpu)\n",
    "y_gpu = cp.asarray(b_cpu)\n",
    "\n",
    "def grade2_cupy(x, y, a, b, c):\n",
    "    return a * x**2 + b * y + c\n",
    "\n",
    "# Benchmark en GPU (incluye copia previa)\n",
    "res = benchmark(\n",
    "    grade2_cupy,\n",
    "    args=(x_gpu, y_gpu, a, b, c),\n",
    "    n_repeat=20\n",
    ")\n",
    "\n",
    "print(f\"Tiempo CuPy con copia CPU->GPU: {cp.mean(res.gpu_times):.4f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec1b08a-5b7d-40a9-91c8-ed52a57f11b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo CuPy sin copia CPU->GPU: 0.0009 s\n"
     ]
    }
   ],
   "source": [
    "# Creación directa de los datos en GPU (sin copia desde CPU)\n",
    "x_gpu = cp.random.rand(size, dtype=cp.float32)\n",
    "y_gpu = cp.random.rand(size, dtype=cp.float32)\n",
    "\n",
    "res = benchmark(\n",
    "    grade2_cupy,\n",
    "    args=(x_gpu, y_gpu, a, b, c),\n",
    "    n_repeat=20\n",
    ")\n",
    "\n",
    "print(f\"Tiempo CuPy sin copia CPU->GPU: {cp.mean(res.gpu_times):.4f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31b19ef-4dc2-4c04-9e7f-61a35a59565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2b\n",
    "\n",
    "from numba import vectorize\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32, float32, float32)'],\n",
    "           target='cuda')\n",
    "def grade2_numba(x, y, a, b, c):\n",
    "    return a * x * x + b * y + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71a9ce5-f482-4500-b6fb-671195839af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo Numba GPU con copia implícita: 0.0090 s\n"
     ]
    }
   ],
   "source": [
    "# Datos en CPU (NumPy)\n",
    "x_cpu = a_cpu.astype(np.float32)\n",
    "y_cpu = b_cpu.astype(np.float32)\n",
    "\n",
    "res = benchmark(\n",
    "    grade2_numba,\n",
    "    args=(x_cpu, y_cpu, np.float32(a), np.float32(b), np.float32(c)),\n",
    "    n_repeat=20\n",
    ")\n",
    "\n",
    "print(f\"Tiempo Numba GPU con copia implícita: {cp.mean(res.gpu_times):.4f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fcd3e23-ff2b-4102-8b61-d603b20e588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo Numba GPU sin contar copia: 0.0015 s\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "# Copia manual de datos a GPU\n",
    "x_dev = cuda.to_device(x_cpu)\n",
    "y_dev = cuda.to_device(y_cpu)\n",
    "\n",
    "res = benchmark(\n",
    "    grade2_numba,\n",
    "    args=(x_dev, y_dev, np.float32(a), np.float32(b), np.float32(c)),\n",
    "    n_repeat=20\n",
    ")\n",
    "\n",
    "print(f\"Tiempo Numba GPU sin contar copia: {cp.mean(res.gpu_times):.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a5fd9-4dd4-4da2-8d83-b12eb3b2827d",
   "metadata": {},
   "source": [
    "Al ejecutar el cálculo en la GPU se observa una reducción muy clara del tiempo de ejecución respecto a la versión en CPU. No obstante, la ganancia obtenida depende en gran medida de cómo se gestionan los datos.\n",
    "\n",
    "En el caso en el que los arrays se copian desde la CPU a la GPU, el cálculo en sí es muy rápido, pero existe un coste adicional asociado a la transferencia de memoria entre ambos dispositivos. Por el contrario, cuando los datos se crean directamente en la GPU, se evita este paso y el tiempo total se reduce de forma significativa.\n",
    "\n",
    "Estos resultados muestran que, en aplicaciones aceleradas por GPU, no solo es importante el cálculo, sino también minimizar las transferencias de datos entre CPU y GPU para obtener el máximo rendimiento.\n",
    "\n",
    "La ejecución en GPU con Numba depende en gran medida del coste de transferencia de datos entre CPU y GPU. Cuando la copia se realiza de forma automática desde arrays en CPU, el tiempo total aumenta. Al copiar los datos previamente a la GPU, se mide únicamente el tiempo de cómputo, obteniéndose un rendimiento claramente superior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b9a1a-393b-47f7-acb9-0bd7fdae13be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

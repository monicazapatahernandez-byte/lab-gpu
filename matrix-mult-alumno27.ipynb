{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454c61ba-825d-4290-b7ed-135a775fe002",
   "metadata": {},
   "source": [
    "### Numpy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8019c56a-e5ce-469b-a406-9c6056ab9c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.44 s ± 24.3 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
      "Result shape: (7000, 7000)\n",
      "Result type: float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: Large matrices (adjust size as needed)\n",
    "n = 7000  # For very large matrices, ensure you have enough RAM\n",
    "A = np.random.rand(n, n).astype(np.float32)\n",
    "B = np.random.rand(n, n).astype(np.float32)\n",
    "\n",
    "C = np.dot(A, B)  # warm-up and Matrix multiplication\n",
    "\n",
    "%timeit -r 2 -o np.dot(A, B)\n",
    "\n",
    "print(f\"Result shape: {C.shape}\")\n",
    "print(f\"Result type: {C.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e79d9cb-ef1e-4380-9362-17ac7b9d8b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA error detected, falling back to CPU\n",
      "CUDA error: no kernel image is available for execution on the device\n",
      "Search for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Device used: cpu\n",
      "Tiempo multiplicación matrices con PyTorch: 1.4828 s\n",
      "Result shape: torch.Size([7000, 7000])\n",
      "Result type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 3.4 PyTorch no compatible asi que cae en CPU\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "n = 7000\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Selección segura de dispositivo\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        device = torch.device(\"cuda\")\n",
    "        A_t = torch.rand((n, n), device=device, dtype=torch.float32)\n",
    "        B_t = torch.rand((n, n), device=device, dtype=torch.float32)\n",
    "        use_cuda = True\n",
    "    except Exception as e:\n",
    "        print(\"CUDA error detected, falling back to CPU\")\n",
    "        print(e)\n",
    "        device = torch.device(\"cpu\")\n",
    "        use_cuda = False\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    use_cuda = False\n",
    "\n",
    "print(\"Device used:\", device)\n",
    "\n",
    "# Crear tensores en el dispositivo final\n",
    "A_t = torch.rand((n, n), device=device, dtype=torch.float32)\n",
    "B_t = torch.rand((n, n), device=device, dtype=torch.float32)\n",
    "\n",
    "# Warm-up\n",
    "C_t = A_t @ B_t\n",
    "if use_cuda:\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "# Medir tiempo\n",
    "start = time.time()\n",
    "C_t = A_t @ B_t\n",
    "if use_cuda:\n",
    "    torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Tiempo multiplicación matrices con PyTorch: {end - start:.4f} s\")\n",
    "print(f\"Result shape: {C_t.shape}\")\n",
    "print(f\"Result type: {C_t.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27895389-3bc0-4edd-bd0d-a001c645639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nSearch for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDevice:\u001b[39m\u001b[33m\"\u001b[39m, device)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Crear tensores\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m A_t = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m B_t = torch.rand((n, n), device=device, dtype=torch.float32)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Warm-up\u001b[39;00m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: no kernel image is available for execution on the device\nSearch for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# 3.4 Para bohr\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Usar el mismo tamaño que en NumPy\n",
    "n = 7000\n",
    "\n",
    "# Selección de dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Crear tensores\n",
    "A_t = torch.rand((n, n), device=device, dtype=torch.float32)\n",
    "B_t = torch.rand((n, n), device=device, dtype=torch.float32)\n",
    "\n",
    "# Warm-up\n",
    "C_t = A_t @ B_t\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "# Medir tiempo (estilo profesor)\n",
    "start = time.time()\n",
    "C_t = A_t @ B_t\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Tiempo multiplicación matrices con PyTorch: {end - start:.4f} s\")\n",
    "print(f\"Result shape: {C_t.shape}\")\n",
    "print(f\"Result type: {C_t.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f57d7-a5dc-42b7-99d0-84106542619f",
   "metadata": {},
   "source": [
    "639 ms ± 3.12 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
    "Result shape: (7000, 7000)\n",
    "Result type: float32\n",
    "CUDA available: True\n",
    "Device used: cuda\n",
    "Tiempo multiplicación matrices con PyTorch: 0.0627 s\n",
    "Result shape: torch.Size([7000, 7000])\n",
    "Result type: torch.float32\n",
    "Device: cuda\n",
    "Tiempo multiplicación matrices con PyTorch: 0.0499 s\n",
    "Result shape: torch.Size([7000, 7000])\n",
    "Result type: torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ca1f8-139a-4d5e-94e9-4c9408f96f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
